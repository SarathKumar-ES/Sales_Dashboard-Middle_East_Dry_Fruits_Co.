{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4ac5smNRZuJ"
   },
   "source": [
    "## Starting a 7-day data challenge to answer one critical business question: Where should the company focus its marketing budget to maximize profit over the next quarter?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I am using the Brazilian E-Commerce public dataset by Olist to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqHRWgnNRmq7"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Nm0SbtBRRq-P"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKxhm7v5R5_2"
   },
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4O2nzlWGR4JU",
    "outputId": "9e7fc230-5963-48c4-e71e-eaf978d2d42f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All core datasets are loaded successfull.\n"
     ]
    }
   ],
   "source": [
    "# 1. Data Loading\n",
    "try:\n",
    "\n",
    "  df_orders = pd.read_csv('olist_orders_dataset.csv')\n",
    "  df_items = pd.read_csv('olist_order_items_dataset.csv')\n",
    "  df_products = pd.read_csv('olist_products_dataset.csv')\n",
    "  df_customers = pd.read_csv('olist_customers_dataset.csv')\n",
    "  print(\"All core datasets are loaded successfull.\")\n",
    "except FileNotFoundError as e:\n",
    "  print(f\"Error: File Not Found. Check File Name and Path: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge 1 Complet. Current size: 112650 rows.\n",
      "Merge 2 Complete. Current size: 112650 rows.\n",
      "Merge 3 Complete. Final size: 112650 rows.\n"
     ]
    }
   ],
   "source": [
    "# Here we are going to join the tables and creating a master table\n",
    "# join 1 Orders to Order item using Order_ID\n",
    "# It is an On to many join since one order can have morethan one item\n",
    "\n",
    "df_master = pd.merge(df_orders, df_items, on='order_id', how='inner')\n",
    "print(f\"Merge 1 Complet. Current size: {df_master.shape[0]} rows.\")\n",
    "\n",
    "# Join 2 Adding product details using product_id\n",
    "\n",
    "df_master = pd.merge(df_master, df_products[['product_id', 'product_category_name']],\n",
    "                     on='product_id', how= 'left')\n",
    "print(f\"Merge 2 Complete. Current size: {df_master.shape[0]} rows.\")\n",
    "\n",
    "# Join 3 Adding customer Location. using customer_id\n",
    "# Taking customers' states as geography\n",
    "df_master = pd.merge(df_master, df_customers[['customer_id', 'customer_state']],\n",
    "                    on='customer_id', how='left')\n",
    "print(f\"Merge 3 Complete. Final size: {df_master.shape[0]} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verification: Preview of the Final Analytical Table ---\n",
      "Shape of the saved table: (108659, 7)\n",
      "                           order_id order_purchase_timestamp  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7         02-10-2017 10:56   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451         24-07-2018 20:41   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d         08-08-2018 08:38   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a         18-11-2017 19:28   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159         13-02-2018 21:18   \n",
      "5  a4591c265e18cb1dcee52889e2d8acc3         09-07-2017 21:57   \n",
      "6  6514b8ad8028c9f2cc2374ded245783f         16-05-2017 13:10   \n",
      "7  76c6e866289321a7c93b82b54852dc33         23-01-2017 18:29   \n",
      "8  e69bfb5eb88e0ed6a785585b27e16dbf         29-07-2017 11:55   \n",
      "9  e6ce16cb79ec1d90b1da9085a6118aeb         16-05-2017 19:41   \n",
      "\n",
      "  order_delivered_customer_date   price  freight_value  product_category_name  \\\n",
      "0              10-10-2017 21:25   29.99           8.72  utilidades_domesticas   \n",
      "1              07-08-2018 15:27  118.70          22.76             perfumaria   \n",
      "2              17-08-2018 18:06  159.90          19.22             automotivo   \n",
      "3              02-12-2017 00:28   45.00          27.20               pet_shop   \n",
      "4              16-02-2018 18:17   19.90           8.72              papelaria   \n",
      "5              26-07-2017 10:57  147.90          27.36             automotivo   \n",
      "6              26-05-2017 12:55   59.99          15.17             automotivo   \n",
      "7              02-02-2017 14:08   19.90          16.05       moveis_decoracao   \n",
      "8              16-08-2017 17:14  149.99          19.77      moveis_escritorio   \n",
      "9              29-05-2017 11:18   99.00          30.53     ferramentas_jardim   \n",
      "\n",
      "  customer_state  \n",
      "0             SP  \n",
      "1             BA  \n",
      "2             GO  \n",
      "3             RN  \n",
      "4             SP  \n",
      "5             PR  \n",
      "6             RJ  \n",
      "7             RS  \n",
      "8             SP  \n",
      "9             RJ  \n",
      "\n",
      "--- Data Types Check ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108659 entries, 0 to 108658\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   order_id                       108659 non-null  object \n",
      " 1   order_purchase_timestamp       108659 non-null  object \n",
      " 2   order_delivered_customer_date  108659 non-null  object \n",
      " 3   price                          108659 non-null  float64\n",
      " 4   freight_value                  108659 non-null  float64\n",
      " 5   product_category_name          108659 non-null  object \n",
      " 6   customer_state                 108659 non-null  object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 5.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read the saved CSV back\n",
    "df_preview = pd.read_csv('olist_master_analytical_table.csv')\n",
    "\n",
    "print(\"\\n--- Verification: Preview of the Final Analytical Table ---\")\n",
    "# Display the shape (rows, columns) to confirm the size\n",
    "print(f\"Shape of the saved table: {df_preview.shape}\")\n",
    "\n",
    "# Display the first 10 rows and all columns\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(df_preview.head(10))\n",
    "\n",
    "print(\"\\n--- Data Types Check ---\")\n",
    "print(df_preview.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleanning Complete, Final Size: 108659 rows.\n",
      "Master Analystical Columns- First 5 Rows\n",
      "<bound method NDFrame.head of                                 order_id order_purchase_timestamp  \\\n",
      "0       e481f51cbdc54678b7cc49136f2d6af7         02-10-2017 10:56   \n",
      "1       53cdb2fc8bc7dce0b6741e2150273451         24-07-2018 20:41   \n",
      "2       47770eb9100c2d0c44946d9cf07ec65d         08-08-2018 08:38   \n",
      "3       949d5b44dbf5de918fe9c16f97b45f8a         18-11-2017 19:28   \n",
      "4       ad21c59c0840e6cb83a9ceb5573f8159         13-02-2018 21:18   \n",
      "...                                  ...                      ...   \n",
      "112645  63943bddc261676b46f01ca7ac2f7bd8         06-02-2018 12:58   \n",
      "112646  83c1379a015df1e13d02aae0204711ab         27-08-2017 14:46   \n",
      "112647  11c177c8e97725db2631073c19f07b62         08-01-2018 21:28   \n",
      "112648  11c177c8e97725db2631073c19f07b62         08-01-2018 21:28   \n",
      "112649  66dea50a8b16d9b4dee7af250b4be1a5         08-03-2018 20:57   \n",
      "\n",
      "       order_delivered_customer_date   price  freight_value  \\\n",
      "0                   10-10-2017 21:25   29.99           8.72   \n",
      "1                   07-08-2018 15:27  118.70          22.76   \n",
      "2                   17-08-2018 18:06  159.90          19.22   \n",
      "3                   02-12-2017 00:28   45.00          27.20   \n",
      "4                   16-02-2018 18:17   19.90           8.72   \n",
      "...                              ...     ...            ...   \n",
      "112645              28-02-2018 17:37  174.90          20.10   \n",
      "112646              21-09-2017 11:24  205.99          65.02   \n",
      "112647              25-01-2018 23:32  179.99          40.59   \n",
      "112648              25-01-2018 23:32  179.99          40.59   \n",
      "112649              16-03-2018 13:08   68.50          18.36   \n",
      "\n",
      "         product_category_name customer_state  \n",
      "0        utilidades_domesticas             SP  \n",
      "1                   perfumaria             BA  \n",
      "2                   automotivo             GO  \n",
      "3                     pet_shop             RN  \n",
      "4                    papelaria             SP  \n",
      "...                        ...            ...  \n",
      "112645                   bebes             SP  \n",
      "112646      eletrodomesticos_2             BA  \n",
      "112647  informatica_acessorios             RJ  \n",
      "112648  informatica_acessorios             RJ  \n",
      "112649            beleza_saude             PR  \n",
      "\n",
      "[108659 rows x 7 columns]>\n",
      "\n",
      "Descriptive Stats Check:\n",
      "               price  freight_value\n",
      "count  108659.000000  108659.000000\n",
      "mean      120.102048      19.982507\n",
      "std       182.112949      15.732586\n",
      "min         0.850000       0.000000\n",
      "25%        39.900000      13.080000\n",
      "50%        74.900000      16.290000\n",
      "75%       134.900000      21.160000\n",
      "max      6735.000000     409.680000\n"
     ]
    }
   ],
   "source": [
    "# droping rowas where KPI or Critical segmentation is not avilable.\n",
    "# Should have a category name to segment and a delivery date for the efficiency KPI\n",
    "\n",
    "df_master.dropna(subset=['product_category_name', 'order_delivered_customer_date'], inplace= True)\n",
    "print(f\"\\nCleanning Complete, Final Size: {df_master.shape[0]} rows.\")\n",
    "\n",
    "# Selecting the final columns for analysis\n",
    "final_columns = ['order_id', 'order_purchase_timestamp', 'order_delivered_customer_date',\n",
    "    'price', 'freight_value', 'product_category_name', 'customer_state'\n",
    "    ]\n",
    "df_master_clean = df_master[final_columns].copy()\n",
    "\n",
    "# Printing the final view\n",
    "print(\"Master Analystical Columns- First 5 Rows\")\n",
    "print(df_master_clean.head)\n",
    "print(\"\\nDescriptive Stats Check:\")\n",
    "print(df_master_clean.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Clean table saved as 'olist_master_analytical_table.csv' for Day 3.\n"
     ]
    }
   ],
   "source": [
    "df_master_clean.to_csv('olist_master_analytical_table.csv', index=False)\n",
    "print(\"\\n Clean table saved as 'olist_master_analytical_table.csv' for Day 3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency KPI (Delivery Time)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I am using Python to calculate the Efficiency KPI (Delivery Time), which was originally planned for the SQL steps\n",
    "1st step- Convert date columns to datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delivery Time feature created.\n"
     ]
    }
   ],
   "source": [
    "df_master_clean['order_purchase_timestamp'] = pd.to_datetime(df_master_clean['order_purchase_timestamp'], format='%d-%m-%Y %H:%M'\n",
    "                                                            )\n",
    "df_master_clean['order_delivered_customer_date'] = pd.to_datetime(df_master_clean['order_delivered_customer_date'],format='%d-%m-%Y %H:%M'\n",
    "                                                                 )\n",
    "\n",
    "# Calculating Delivery time in days for finding efficiency KPI\n",
    "df_master_clean['delivery_time_days'] = (df_master_clean['order_delivered_customer_date'] - df_master_clean['order_purchase_timestamp']).dt.total_seconds()/(60*60*24)\n",
    "\n",
    "# To handle negative/zero delivery times for data integrity\n",
    "df_master_clean.loc[df_master_clean['delivery_time_days']<= 0, 'delivery_time_days'] = np.nan\n",
    "\n",
    "print(\"Delivery Time feature created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Revenue and Efficiancy KPIs "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We are going to use groupby to calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " KPIs Calculated!!!\n",
      "------------------------\n",
      "\n",
      "Top 5 Revenue Categories:\n",
      "      product_category_name  Total_Revenue_Dollars  Total_Orders  Order_Shipped\n",
      "11            beleza_saude             1233211.61          8649           8649\n",
      "66      relogios_presentes             1165898.98          5493           5493\n",
      "13         cama_mesa_banho             1023434.76          9272           9272\n",
      "32           esporte_lazer              954695.05          7530           7530\n",
      "44  informatica_acessorios              888613.62          6529           6529\n"
     ]
    }
   ],
   "source": [
    "# Revenue and Odrers by Category\n",
    "df_revenue_kpi = df_master_clean.groupby('product_category_name').agg(\n",
    "    Total_Revenue_Dollars=('price', 'sum'),\n",
    "    Total_Orders=('order_id', 'nunique'),\n",
    "    Order_Shipped=('order_id', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "# Efficiancy By State\n",
    "df_efficiency_kpi = df_master_clean.groupby('customer_state').agg(\n",
    "    Avg_Delivery_Time_Days=('delivery_time_days', 'mean'),\n",
    "    Orders_Shipped=('order_id', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\n KPIs Calculated!!!\")\n",
    "print(\"------------------------\")\n",
    "print(\"\\nTop 5 Revenue Categories:\\n\", df_revenue_kpi.sort_values(by='Total_Revenue_Dollars', ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files saved for Day 4 EDA and Day 5 Visualization.\n"
     ]
    }
   ],
   "source": [
    "# Saving these data for Visualisation\n",
    "df_revenue_kpi.to_csv('kpi_revenue_by_category.csv', index=False)\n",
    "df_efficiency_kpi.to_csv('kpi_efficiency_by_state.csv', index=False)\n",
    "\n",
    "print(\"\\nFiles saved for Day 4 EDA and Day 5 Visualization.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
